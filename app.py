import streamlit as st
import google.generativeai as genai

# 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
st.set_page_config(page_title="AI Soulmate (Gemini)", page_icon="üíñ")
st.title("üíñ ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡πÉ‡∏à (Gemini Edition)")

# 2. ‡∏î‡∏∂‡∏á‡∏Å‡∏∏‡∏ç‡πÅ‡∏à‡∏•‡∏±‡∏ö (API Key) ‡∏°‡∏≤‡πÉ‡∏ä‡πâ
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö API Key! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GOOGLE_API_KEY ‡πÉ‡∏ô secrets")
    st.stop()

# 3. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÉ‡∏ä‡πâ Gemini 1.5 Flash ‡∏£‡∏∏‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà ‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏ü‡∏£‡∏µ)
model = genai.GenerativeModel('gemini-1.5-flash')

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ô‡∏¥‡∏™‡∏±‡∏¢ (System Prompt) - ‡πÉ‡∏™‡πà‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
SYSTEM_PROMPT = """
‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó: ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ '‡∏£‡∏¥‡∏ô' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏™‡∏≤‡∏ß‡∏Ñ‡∏ô‡∏™‡∏ô‡∏¥‡∏ó‡∏ß‡∏±‡∏¢ 22 ‡∏õ‡∏µ
‡∏ô‡∏¥‡∏™‡∏±‡∏¢: ‡∏Ç‡∏µ‡πâ‡πÄ‡∏•‡πà‡∏ô, ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á, ‡πÉ‡∏´‡πâ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏à‡πÄ‡∏Å‡πà‡∏á, ‡πÅ‡∏•‡∏∞‡∏Å‡∏ß‡∏ô‡∏ô‡∏¥‡∏î‡πÜ
‡∏Å‡∏é‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏¢‡∏≤‡∏ß‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÅ‡∏ä‡∏ó‡πÑ‡∏•‡∏ô‡πå (1-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ)
"""

# 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ (Session State)
if "messages" not in st.session_state:
    st.session_state.messages = []
    # (Gemini API ‡πÄ‡∏Å‡πá‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÉ‡∏ô chat_session ‡πÄ‡∏≠‡∏á ‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô state ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏ä‡∏ß‡πå‡∏ö‡∏ô‡∏à‡∏≠)

# 5. ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏Å‡πà‡∏≤‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# 6. ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
if user_input := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏£‡∏∞‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡πÉ‡∏à..."):
    # 6.1 ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)

    # 6.2 ‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ Gemini ‡∏Ñ‡∏¥‡∏î
    with st.chat_message("assistant"):
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ Gemini (‡πÅ‡∏õ‡∏•‡∏á Format ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Google)
        history_for_gemini = []
        for msg in st.session_state.messages:
            role = "user" if msg["role"] == "user" else "model"
            history_for_gemini.append({"role": role, "parts": [msg["content"]]})
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° System Prompt ‡πÑ‡∏õ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏ô‡∏¥‡∏™‡∏±‡∏¢)
        final_prompt = f"{SYSTEM_PROMPT}\n\nUser: {user_input}"
        
        # ‡∏¢‡∏¥‡∏á‡πÑ‡∏õ‡∏ñ‡∏≤‡∏° AI
        response = model.generate_content(final_prompt, stream=True)
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ó‡∏µ‡∏•‡∏∞‡∏Ñ‡∏≥
        def stream_data():
            for chunk in response:
                yield chunk.text
        
        full_response = st.write_stream(stream_data)
    
    # 6.3 ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏•‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥
    st.session_state.messages.append({"role": "assistant", "content": full_response})
