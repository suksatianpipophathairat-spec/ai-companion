import streamlit as st
import google.generativeai as genai

# 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
st.set_page_config(page_title="AI Soulmate (Gemini)", page_icon="üíñ")
st.title("üíñ ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡πÉ‡∏à (Gemini Edition)")

# 2. ‡∏î‡∏∂‡∏á‡∏Å‡∏∏‡∏ç‡πÅ‡∏à‡∏•‡∏±‡∏ö (API Key) ‡∏°‡∏≤‡πÉ‡∏ä‡πâ
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö API Key! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GOOGLE_API_KEY ‡πÉ‡∏ô secrets")
    st.stop()

# 3. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏ó‡∏û‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏à‡∏≠!)
# ‡πÄ‡∏£‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å gemini-2.0-flash ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏â‡∏•‡∏≤‡∏î‡∏°‡∏≤‡∏Å
model = genai.GenerativeModel('gemini-flash-latest')

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ô‡∏¥‡∏™‡∏±‡∏¢ (System Prompt) - ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ô‡∏¥‡∏™‡∏±‡∏¢
SYSTEM_PROMPT = """
‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó: ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ '‡∏£‡∏¥‡∏ô' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏™‡∏≤‡∏ß‡∏Ñ‡∏ô‡∏™‡∏ô‡∏¥‡∏ó‡∏ß‡∏±‡∏¢ 22 ‡∏õ‡∏µ
‡∏ô‡∏¥‡∏™‡∏±‡∏¢: ‡∏Ç‡∏µ‡πâ‡πÄ‡∏•‡πà‡∏ô, ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á, ‡πÉ‡∏´‡πâ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏à‡πÄ‡∏Å‡πà‡∏á, ‡πÅ‡∏•‡∏∞‡∏Å‡∏ß‡∏ô‡∏ô‡∏¥‡∏î‡πÜ
‡∏Å‡∏é‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏¢‡∏≤‡∏ß‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÅ‡∏ä‡∏ó‡πÑ‡∏•‡∏ô‡πå (1-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ)
"""

# 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ (Session State)
if "messages" not in st.session_state:
    st.session_state.messages = []

# 5. ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏Å‡πà‡∏≤‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# 6. ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
if user_input := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏£‡∏∞‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡πÉ‡∏à..."):
    # 6.1 ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)

    # 6.2 ‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ Gemini ‡∏Ñ‡∏¥‡∏î
    with st.chat_message("assistant"):
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ Gemini
        history_for_gemini = []
        for msg in st.session_state.messages:
            role = "user" if msg["role"] == "user" else "model"
            history_for_gemini.append({"role": role, "parts": [msg["content"]]})
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° System Prompt ‡πÑ‡∏õ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        final_prompt = f"{SYSTEM_PROMPT}\n\nUser: {user_input}"
        
        # ‡∏¢‡∏¥‡∏á‡πÑ‡∏õ‡∏ñ‡∏≤‡∏° AI (‡∏î‡∏±‡∏Å‡∏à‡∏±‡∏ö Error ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤)
        try:
            response = model.generate_content(final_prompt, stream=True)
            # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ó‡∏µ‡∏•‡∏∞‡∏Ñ‡∏≥
            def stream_data():
                for chunk in response:
                    if chunk.text:
                        yield chunk.text
            full_response = st.write_stream(stream_data)
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
            full_response = "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏ô‡∏∞ ‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á... ‡∏û‡∏≠‡∏î‡∏µ‡∏£‡∏¥‡∏ô‡∏°‡∏∂‡∏ô‡∏´‡∏±‡∏ß‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢ (‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á) ‡∏•‡∏≠‡∏á‡∏ó‡∏±‡∏Å‡∏°‡∏≤‡πÉ‡∏´‡∏°‡πà‡∏ô‡∏∞ ü•∫"
    
    # 6.3 ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏•‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥
    st.session_state.messages.append({"role": "assistant", "content": full_response})

